<!--?xml version="1.0" encoding="UTF-8" standalone="no"?--><html><head><title>Chapter&#xA0;25.&#xA0;Optical Tracking</title><link rel="stylesheet" type="text/css" href="core.css"><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"><link rel="up" href="pt04.html" title="Part&#xA0;IV.&#xA0;Digital Physics"><link rel="prev" href="ch24.html" title="Chapter&#xA0;24.&#xA0;3D Display"><link rel="next" href="ch26.html" title="Chapter&#xA0;26.&#xA0;Sound"></head><body>
         
        <script>
        function ok(){ 
            window.gggs()
            return;
            //$('#musicPlayer').parent().remove();
            //speakTransportPanelDialogV2.closeEmoteDialog()
            //speakTransportPanelDialog.closeEmoteDialog()
            //
            debugger
            let url = 'http://127.0.0.1:8080/uploads/extracted/' +
             'Crazy Rich Asians  Kevin Kwanepub/' +
              'jsonSets/OEBPS/Kwan_9780385536981_epub_prl_r1.htm.html.sentences.json'
            speakTransportPanelDialogV2.sideLoadSentences2(null, null, null, url)
            
        }
        setTimeout(ok, 1500)
        </script>
        <div style="background:white">````````</div><section class="chapter" title="Chapter&#xA0;25.&#xA0;Optical Tracking" epub:type="chapter" id="optical_tracking"><div class="titlepage"><div><div><h2 class="title"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">1</span><span sentence-index="13379" class="">Chapter&#xA0;25.&#xA0;Optical  Tracking</span></span></h2></div></div></div><p><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13380</span><span sentence-index="13380" class="">In  previous  chapters  we  discussed  how  accelerometers  have  changed  the    way  that  people  interact  with  video  games. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">3</span><span sentence-index="13381" class=""> The  same  sort  of  innovation  is    occurring  with  </span></span><a id="I_indexterm6_id362222" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13382</span><span sentence-index="13382" class="">optical  sensors. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13383</span><span sentence-index="13383" class="">  Cameras,  both  in  visual  and  infrared    spectrums,  are  being  used  to  generate  input  for  games. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13384</span><span sentence-index="13384" class="">  This  chapter  will    focus  on  the  Microsoft  Kinect  for  Windows  SDK  and  give  an  overview  of  how  to    make  a  simple  game  that  combines  optical  tracking  with  physics. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13385</span><span sentence-index="13385" class="">  First  we&apos;ll    give  a  short  introduction  on  the  technologies  these  systems  use  to  turn  a    camera  into  a  tracking  device.</span></span></a></p><p><a id="I_indexterm6_id362222" class="indexterm"><span class="nonQuoteStr" gspkNameUnknown="First" gsIndex="1"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13388</span><span sentence-index="13388" class="">Without  getting  too  detailed,  we  should  start  by  discussing  a  few    things  about  digital  cameras. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13389</span><span sentence-index="13389" class=""><span> </span><span class="personQuoteSpeaker" whospk="first">First</span><span>, most of us are familiar with the </span></span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13390</span><span sentence-index="13390" class="" gspkNameUnknown="First" gsIndex="1"> &quot;megapixel&quot; </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13391</span><span sentence-index="13391" class="">  metric  used  to  describe  digital  cameras. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13392</span><span sentence-index="13392" class="">  This  number  is  a    measure  of  how  many  pixels  of  information  the  camera  records  in  a  single    frame. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13393</span><span sentence-index="13393" class="">  It  is  equal  to  the  height  of  the  frame  in  pixels  multiplied  by  the    width  of  the  frame  in  pixels. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13394</span><span sentence-index="13394" class="">  A  pixel,  or  picture  element,  contains    information  on  intensity,  color,  and  the  location  of  the  pixel  relative  to    some  origin. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13395</span><span sentence-index="13395" class="">  The  amount  of  information  depends  on  the  bits  per  pixel  and    corresponds  to  the  amount  of  color  variation  a  particular  pixel  can  display. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13396</span><span sentence-index="13396" class="">    Perhaps  you&apos;ve  seen  your  graphics  set  to  16-bit  or  24-bit  modes. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13397</span><span sentence-index="13397" class="">  This    describes  how  many  colors  a  particular  pixel  can  display. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13398</span><span sentence-index="13398" class="">  A  24-bit  pixel  can    be  one  of  16.8  million  different  colors  at  any  instant. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13399</span><span sentence-index="13399" class="">  It  is  commonly  held    that  the  human  eye  can  differentiate  among  about  10  million  colors;  24-bit    color  is  called  </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13400</span><span sentence-index="13400" style="border-bottom: solid orange 4px;" class="" gspkNameUnknown="First" gsIndex="1"> &quot;true  color,&quot; </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13401</span><span sentence-index="13401" class="">  as  it  can  display  more  colors  than  your  eye    can  recognize. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13402</span><span sentence-index="13402" class="">  You  might  also  see  32-bit  color  modes;  these  include  an  extra    8  bits  for  a  transparency  channel  that  tells  the  computer  what  to  do  if  this    image  were  put  on  top  of  another  image. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">25</span><span sentence-index="13403" class=""> This  is  sometimes  referred  to    </span></span></a><a id="I_indexterm6_id362250" class="indexterm"></a><a id="I_indexterm6_id362256" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">27</span><span sentence-index="13405" class="">as  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">27</span><span sentence-index="13405" class="">opacity</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">27</span><span sentence-index="13405" class=""> or    </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">27</span><span sentence-index="13405" class="">alpha</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13405</span><span sentence-index="13405" class=""> .</span></span></a></p><p><a id="I_indexterm6_id362256" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">30</span><span sentence-index="13408" class="">Optical  tracking  and  computer  vision,  in  general,  work  by  detecting    </span></span></a><a id="I_indexterm6_id362274" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13409</span><span sentence-index="13409" class="">patterns  in  this  wealth  of  pixel  data. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13410</span><span sentence-index="13410" class="">  Pattern  recognition  is    a  mature  field  of  computer  science  research. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13411</span><span sentence-index="13411" class="">  The  human  brain  is  an  excellent    pattern  recognizer. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">34</span><span sentence-index="13412" class=""> For  instance,  look  at  </span></span></a><a class="xref" href="ch25.html#four_unrelated_geometric_entities" title="Figure&#xA0;25-1.&#xA0;Four unrelated geometric entities"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">35</span><span sentence-index="13413" class="">Figure&#xA0;25-1</span></span></a><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13414</span><span sentence-index="13414" class=""> . </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13415</span><span sentence-index="13415" class="">  Most  of  us  can&apos;t  help  but    see  a  face  in  what  is  in  reality  a  collection  of  three  random  shapes. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13416</span><span sentence-index="13416" class="">  Our    brains  are  so  primed  to  recognize  the  basic  pattern  of  a  human  face  that  we    can  do  it  even  when  we  don&apos;t  want  to!</span></span></p><div class="figure"><a id="four_unrelated_geometric_entities"></a><div class="figure-contents"><a id="four_unrelated_geometric_entities"></a><div class="mediaobject"><a id="four_unrelated_geometric_entities"></a><a id="I_mediaobject6_id362302"><img src="httpatomoreillycomsourceoreillyimages1599020.png.jpg" alt="Four unrelated geometric entities"></a></div></div><div class="figure-title"><a id="I_mediaobject6_id362302"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">44</span><span sentence-index="13422" class="">Figure&#xA0;25-1.&#xA0;Four  unrelated  geometric  entities</span></span></a></div></div><p><a id="I_mediaobject6_id362302"><span class="nonQuoteStr" gspkNameUnknown="Computers" gsIndex="2"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13424</span><span sentence-index="13424" class=""><span class="personQuoteSpeaker" whospk="computers">Computers</span><span>, on the other hand, have a harder time looking at two circles and a few lines and saying, </span></span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13425</span><span sentence-index="13425" style="border-bottom: solid orange 4px;" class="" gspkNameUnknown="Computers" gsIndex="2"> &quot;Hey,  this  is  a  smiling  face.&quot;</span></span></a></p><div class="sect1" title="Sensors and SDKs"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="sensors_and_sdks"><a id="I_mediaobject6_id362302"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">50</span><span sentence-index="13428" class="">Sensors  and  SDKs</span></span></a></h2></div></div></div><p><a id="I_mediaobject6_id362302"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">52</span><span sentence-index="13430" class="">The  modern  </span></span></a><a id="I_indexterm6_id362336" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13431</span><span sentence-index="13431" class="">interest  in  computer  vision  as  a  consumer  input  for  computer        games  has  led  to  the  development  of  several  SDKs  for  performing        computer-vision  pattern  recognition. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13432</span><span sentence-index="13432" class="">  One  such  system  is  Kinect  for        Windows. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13433</span><span sentence-index="13433" class="">  Although  Microsoft  provides  a  very  high-level  API  with  the        Kinect,  the  downside  is  that  you  are  locked  into  its  hardware. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13434</span><span sentence-index="13434" class="">  The  popular        open  source  alternative  is  OpenCV,  a  library  of  computer-vision        algorithms. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13435</span><span sentence-index="13435" class="">  Its  advantage  is  that  it  can  use  a  wide  variety  of  camera        hardware  and  not  just  the  Kinect  sensor.</span></span></a></p><div class="sect2" title="Kinect"><div class="titlepage"><div><div><h3 class="title" id="kinect"><a id="I_indexterm6_id362336" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">60</span><span sentence-index="13438" class="">Kinect</span></span></a></h3></div></div></div><p><a id="I_indexterm6_id362336" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">62</span><span sentence-index="13440" class="">The  Kinect  was  </span></span></a><a id="I_indexterm6_id362364" class="indexterm"></a><a id="I_indexterm6_id362376" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13442</span><span sentence-index="13442" class="">originally  developed  for  the  Xbox  360  but  has  recently            been  rebranded  to  include  Kinect  for  Windows. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13443</span><span sentence-index="13443" class="">  As  console  game  design  has            high  entrance  requirements,  the  Kinect  for  Windows  allows  more  casual            developers  to  try  their  hand  at  creating  games  with  optical  input. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13444</span><span sentence-index="13444" class="">  The            system  has  a  hardware  component,  called  the  Kinect  sensor,  and  the            previously  mentioned  Kinect  SDK  that  does  a  lot  of  the  heavy  lifting  for            us  in  terms  of  pattern  recognition  and  depth  sensing. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13445</span><span sentence-index="13445" class="">  The  hardware            component  consists  of  an  infrared  projector,  infrared  camera,  visible            light  camera,  and  an  array  of  microphones. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13446</span><span sentence-index="13446" class="">  The  two  cameras  and  the            projector  form  the  basis  of  the  optical  tracking  system. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13447</span><span sentence-index="13447" class="">  The  projector            sends  out  infrared  light  that  is  invisible  to  humans. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13448</span><span sentence-index="13448" class="">  This  light  bounces            off  objects  and  is  reflected  back  to  the  Kinect. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13449</span><span sentence-index="13449" class="">  The  infrared  camera            records  the  reflected  light  pattern,  and  based  on  how  it  has  been            distorted,  calculates  how  far  the  object  is  from  the  sensor. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13450</span><span sentence-index="13450" class="">  This  exact            method  is  carried  out  in  the  hardware  of  the  sensor  and  is  proprietary. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13451</span><span sentence-index="13451" class="">            However,  the  patent  applications  reveal  that  a  special  lens  projects            circles  that,  when  reflected,  become  ellipses  of  varying  shapes. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13452</span><span sentence-index="13452" class="">  The            shape  of  the  ellipse  depends  on  the  depth  of  the  object  reflecting  it. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">75</span><span sentence-index="13453" class="">           In  general,  this  is  a  much-improved  </span></span></a><a id="I_indexterm6_id362394" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">76</span><span sentence-index="13454" class="">version  of  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">76</span><span sentence-index="13454" class="">depth  from  focus</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13455</span><span sentence-index="13455" class=""> ,  in  which            the  computer  assumes  that  blurry  objects  are  farther  away  than  objects            in  focus.</span></span></a></p><p><a id="I_indexterm6_id362394" class="indexterm"><span class="nonQuoteStr" gspkNameUnknown="narrator" gsIndex="3"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13458</span><span sentence-index="13458" class="">As  for  object  detection,  the  Kinect  comes  with  a  great  set  of            algorithms  for  skeleton  direction. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13459</span><span sentence-index="13459" class="">  It  can  also  be  trained  to  detect            other  objects,  but  skeleton  detection  is  really  its  forte. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13460</span><span sentence-index="13460" class="">  The  skeleton            detection  is  good  because  of  the  massive  amount  of  training  Microsoft            used  for  the  algorithms  when  creating  the  SDK. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13461</span><span sentence-index="13461" class="">  If  you  were  to  use  an            average  computer  to  run  the  Kinect  skeleton  training  program,  it  would            take  about  three  years. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13462</span><span sentence-index="13462" class="">  Luckily,  Microsoft  had  1,000  computers  lying            around,  so  it  takes  them  only  a  day  to  run  the  training  simulation. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13463</span><span sentence-index="13463" class="">  This            gives  you  an  idea  of  the  amount  of  training  you  need  to  provide  for            consumer-level  tracking  in  your  own  algorithms. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13464</span><span sentence-index="13464" class="">  The  Kinect  can  track  up            to  six  people  with  two  of  them  being  in  </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13465</span><span sentence-index="13465" class="" gspkNameUnknown="narrator" gsIndex="3"> &quot;active&quot; </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13466</span><span sentence-index="13466" class="">  mode. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13467</span><span sentence-index="13467" class="">  For  these  2            people,  20  individual  joints  are  tracked. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13468</span><span sentence-index="13468" class="">  The  sensor  can  also  track            people  while  standing  or  sitting.</span></span></a></p></div><div class="sect2" title="OpenCV"><div class="titlepage"><div><div><h3 class="title" id="opencv"><a id="I_indexterm6_id362394" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">93</span><span sentence-index="13471" class="">OpenCV</span></span></a></h3></div></div></div><p><a id="I_indexterm6_id362394" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">95</span><span sentence-index="13473" class="">The  OpenCV  method  </span></span></a><a id="I_indexterm6_id362434" class="indexterm"></a><a id="I_indexterm6_id362444" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13475</span><span sentence-index="13475" class="">for  3D  reconstruction  is,  well,  more  open! </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13476</span><span sentence-index="13476" class="">  The  library  is            designed  to  work  with  any  common  webcam  or  other  camera  you  can  get            connected  to  your  computer. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13477</span><span sentence-index="13477" class="">  OpenCV  works  well  with  stereoscopic  cameras            and  is  also  capable  of  attempting  to  map  depth  with  a  single  camera. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13478</span><span sentence-index="13478" class="">            However,  those  results  would  not  be  accurate  enough  to  control  a  game,            so  we  suggest  you  stick  with  two  cameras  if  you&apos;re  trying  to  use  regular            webcams.</span></span></a></p><p><a id="I_indexterm6_id362444" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13481</span><span sentence-index="13481" class="">Indeed,  finding  depth  is  relatively  straightforward  using  OpenCV. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">104</span><span sentence-index="13482" class=""> The  built-in  function                    </span></span><code class="literal"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">104</span><span sentence-index="13482" class="">ReprojectImageTo3D</span></span></code><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">104</span><span sentence-index="13482" class=""> calculates  a  vector  for  each  pixel                    (</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">104</span><span sentence-index="13482" class="">x</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">104</span><span sentence-index="13482" class="">,</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">104</span><span sentence-index="13482" class="">y</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">104</span><span sentence-index="13482" class="">)  based  on  a  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">104</span><span sentence-index="13482" class="">disparity                    map</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13482</span><span sentence-index="13482" class=""> . </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">105</span><span sentence-index="13483" class=""> A  disparity  map</span></span></a><a id="I_indexterm6_id362480" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">106</span><span sentence-index="13484" class=""> is  a  data  set  that  describes  how  pixels  have  changed  from  one  image  to  the                next;  if  you  have  stereoscopic  cameras,  this  essentially  is  the  reverse  of  the  technique  we                use  in  </span></span></a><a class="xref" href="ch24.html" title="Chapter&#xA0;24.&#xA0;3D Display"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">108</span><span sentence-index="13486" class="">Chapter&#xA0;24</span></span></a><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13486</span><span sentence-index="13486" class="">  when  dealing  with  3D  displays. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">109</span><span sentence-index="13487" class=""> To  create  a  disparity  map,                OpenCV  provides  the  handy  function  </span></span><code class="literal"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">109</span><span sentence-index="13487" class="">FindStereoCorrespondenceGC()</span></span></code><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13487</span><span sentence-index="13487" class=""> . </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13488</span><span sentence-index="13488" class="">  This  function  takes  a  set  of  images,  assumes  them                to  be  from  a  sterescopic  source,  and  generates  a  disparity  map  by  systematically  comparing                them. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">111</span><span sentence-index="13489" class=""> The  documentation  is  very  complete,  and  there  are  several  books  on  the  subject  of                OpenCV,  including  </span></span><a class="ulink" href="http://shop.oreilly.com/product/0636920022497.do" target="_top"><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">112</span><span sentence-index="13490" class="">Learning  OpenCV</span></span></em></span></a><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">112</span><span sentence-index="13490" class=""> by  </span></span><a id="I_indexterm6_id362512" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">114</span><span sentence-index="13492" class="">Gary  Bradski  and  Adrian  Kaehler</span></span></a><a id="I_indexterm6_id362520" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13493</span><span sentence-index="13493" class="">  (O&apos;Reilly),  so  we  again  will  save  the  details  for  independent  study.</span></span></a></p><p><a id="I_indexterm6_id362520" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">118</span><span sentence-index="13496" class="">Object  detection  is  also  </span></span></a><a id="I_indexterm6_id362529" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13497</span><span sentence-index="13497" class="">possible  with  OpenCV. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">120</span><span sentence-index="13498" class=""> The  common  example  in  the  OpenCV            project  uses  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">120</span><span sentence-index="13498" class="">Harr-like</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">120</span><span sentence-index="13498" class=""> features  to  </span></span></a><a id="I_indexterm6_id362540" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13499</span><span sentence-index="13499" class="">recognize  objects. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13500</span><span sentence-index="13500" class="">  These  features  are  rectangles  whose            mathematical  structure  allows  for  very  fast  computation. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13501</span><span sentence-index="13501" class="">  By  developing            patterns  of  these  rectangles  for  a  given  object,  a  program  can  detect            objects  out  of  the  background. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13502</span><span sentence-index="13502" class="">  For  example,  one  such  pattern  could  be  if            a  selection  rectangle  includes  an  edge. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13503</span><span sentence-index="13503" class="">  The  program  would  detect  an  edge            in  the  pixel  data  by  finding  a  sharp  gradient  between  color  and/or  other            attributes. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13504</span><span sentence-index="13504" class="">  If  you  detect  the  right  number  of  edges  in  the  right            position,  you  have  detected  your  object.</span></span></a></p><p><a id="I_indexterm6_id362540" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13507</span><span sentence-index="13507" class="">Hardcoding  a  pattern  for  the  computer  to  look  for  would  result  in            a  very  narrow  set  of  recognition  criteria. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13508</span><span sentence-index="13508" class="">  Therefore,  computer-vision            algorithms  rely  on  a  system  of  training  rather  than  hard  programming. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">131</span><span sentence-index="13509" class="">           Specifically,  they  use  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">131</span><span sentence-index="13509" class="">cascade  classifier            training</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13509</span><span sentence-index="13509" class=""> .</span></span></a></p><p><a id="I_indexterm6_id362540" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13512</span><span sentence-index="13512" class="">The  training  process  works  well  but  requires  a  large  image  set. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13513</span><span sentence-index="13513" class="">            Typical  examples  require  6,000  negative  images  and  1,500  positive            images. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13514</span><span sentence-index="13514" class="">  The  negative  images  are  commonly  called  background  images. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13515</span><span sentence-index="13515" class="">  When            training  the  algorithm,  you  take  1,200  of  your  positive  images  and  draw            selection  rectangles  around  the  object  you  are  trying  to  detect. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13516</span><span sentence-index="13516" class="">  The            computer  learns  that  the  pattern  in  the  selection  rectangles  you&apos;ve            given  it  is  one  to  be  identified. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13517</span><span sentence-index="13517" class="">  This  will  take  the  average  computer  a            long,  long  time. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13518</span><span sentence-index="13518" class="">  The  remaining  images  are  used  for  testing  to  ensure            that  your  algorithm  has  satisfactory  accuracy  in  detecting  the  patterns            you&apos;ve  shown  it. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13519</span><span sentence-index="13519" class="">  The  larger  the  sample  set,  including  different            lighting,  the  more  accurate  the  system  will  be. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">142</span><span sentence-index="13520" class=""> Once  the  algorithm  is            trained  to  detect  a  particular  object,  all  you  need  is  the  training            file&#x2014;usually  an  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">142</span><span sentence-index="13520" class="">.xml</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13520</span><span sentence-index="13520" class="">  file&#x2014;to  share  that  training            with  another  computer.</span></span></a></p></div></div><div class="sect1" title="Numerical Differentiation"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="numerical_differentiation"><a id="I_indexterm6_id362540" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">145</span><span sentence-index="13523" class="">Numerical  Differentiation</span></span></a></h2></div></div></div><p><a id="I_indexterm6_id362540" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">147</span><span sentence-index="13525" class="">As  previously  noted,  </span></span></a><a id="op25.2" class="indexterm"></a><a id="di25.2" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13527</span><span sentence-index="13527" class="">there  are  many  ways  to  collect  optical  tracking  data,  but        since  we  are  focusing  on  the  physics  aspects,  we&apos;ll  now  talk  about  how  to        process  the  data  to  get  meaningfully  physical  simulation. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13528</span><span sentence-index="13528" class="">  By  combining        object  detection  with  depth  sensing,  we  can  detect  and  then  track  an        object  as  it  moves  in  the  camera&apos;s  field  of  vision. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">151</span><span sentence-index="13529" class=""> Let&apos;s  assume  that  you        have  used  the  frame  rate  or  internal  clock  to  generate  data  of  the        following  format:</span></span></a></p><a id="I_programlisting6_id362625"><pre class="programlisting">{(x[i],y[i],z[i],t[i]),(x[i+1],y[i+1],z[i+1],t[i+1]) ,
(x[i+2],y[i+2],z[i+2],t[i+2]), ...}</pre><p><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13531</span><span sentence-index="13531" class="">Now,  a  single  data  point  consisting  of  three  coordinates  and  a        timestamp  doesn&apos;t  allow  us  to  determine  what  is  going  on  with  an  object&apos;s        velocity  or  acceleration. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13532</span><span sentence-index="13532" class="">  However,  as  the  camera  is  supplying  new  position        data  at  around  20&#x2013;30  Hz,  we  will  generate  a  time  history  of  position  or        displacement. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13533</span><span sentence-index="13533" class="">  Using  techniques  similar  to  the  numerical  integration  we        used  to  take  acceleration  and  turn  it  into  velocities  and  then  turn  those        velocities  into  position  in  earlier  chapters,  we  can  apply  numerical        differentiation  to  accomplish  the  reverse. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13534</span><span sentence-index="13534" class="">  Specifically,  we  can  use  the        finite  difference  method.</span></span></p></a><p><a id="I_programlisting6_id362625"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13537</span><span sentence-index="13537" class="">For  velocity,  we  need  a  first-order  finite  difference  numerical        differentiation  scheme. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13538</span><span sentence-index="13538" class="">  Because  we  know  the  current  data  point  and  the        previous  data  point,  we  are  looking  backward  in  time  to  get  the  current        position. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">161</span><span sentence-index="13539" class=""> This  is  known  </span></span></a><a id="I_indexterm6_id362645" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">162</span><span sentence-index="13540" class="">as  the  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">162</span><span sentence-index="13540" class="">backward  difference  scheme</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13541</span><span sentence-index="13541" class=""> . </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">164</span><span sentence-index="13542" class=""> In        general,  the  backward  difference  is  given  by:</span></span></a></p><table style="border: 0; " class="simplelist"><tbody><tr><td><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">164</span><span sentence-index="13542" class="">f&apos;(x)  =  lim  h&#x2192;0  (f(x+h)  &#x2013;  f(x))  /  h</span></span></td></tr></tbody></table><p><a id="I_indexterm6_id362645" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13544</span><span sentence-index="13544" class="">We  must  use  the  backward  difference  for  the  first-order        differentiation,  as  we  know  only  the  present  position  and  past  positions. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">167</span><span sentence-index="13545" class="">       In  our  case,  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">167</span><span sentence-index="13545" class="">h</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13545</span><span sentence-index="13545" class="">  is  the  difference  in  time  between  two        data  points  and  has  a  nonzero,  fixed  value. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">168</span><span sentence-index="13546" class=""> Therefore,  the  equation  can  be        rewritten  as:</span></span></a></p><table style="border: 0; " class="simplelist"><tbody><tr><td><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">168</span><span sentence-index="13546" class="">(f(x+h)  &#x2013;  f(x))  /  h  =  &#x2206;f(x)/h</span></span></td></tr></tbody></table><p><a id="I_indexterm6_id362645" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">170</span><span sentence-index="13548" class="">where  &#x2206;</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">170</span><span sentence-index="13548" class="">f</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">170</span><span sentence-index="13548" class="">(</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">170</span><span sentence-index="13548" class="">x</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">170</span><span sentence-index="13548" class="">)  is  the        position  at  the  second  timestamp  minus  the  position  at  the  first        timestamp,  and  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">170</span><span sentence-index="13548" class="">h</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13548</span><span sentence-index="13548" class="">  is  the  difference  in  time. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13549</span><span sentence-index="13549" class="">  This  is        relatively  straightforward,  as  we  are  just  calculating  the  distance        traveled  divided  by  the  time  it  took  to  travel  that  distance. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13550</span><span sentence-index="13550" class="">  This  is  the        definition  of  average  velocity.</span></span></a></p><p><a id="I_indexterm6_id362645" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">175</span><span sentence-index="13553" class="">Note  that  because  we  are  finding  the  average  velocity  between  the  two  data  points,  if  the            time  delta,  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">175</span><span sentence-index="13553" class="">h</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13553</span><span sentence-index="13553" class=""> ,  is  too  large,  this  will  not  accurately  approximate  the            instantaneous  velocity  of  the  object. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13554</span><span sentence-index="13554" class="">  You  may  be  tempted  to  push  whatever  hardware  you  have  to            its  limit  and  get  the  highest  possible  sampling  rate;  however,  if  the  time  step  is  too  small,            the  subtraction  of  one  displacement  from  another  will  result  in  significant  round-off  error            using  floating-point  arithmetic. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">177</span><span sentence-index="13555" class=""> You  must  take  care  to  ensure  that  when  you&apos;re  selecting  a            timestamp,  (</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">177</span><span sentence-index="13555" class="">t[i]  +  h</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">177</span><span sentence-index="13555" class="">)  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">177</span><span sentence-index="13555" class="">&#x2013;  t</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">177</span><span sentence-index="13555" class="">[</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">177</span><span sentence-index="13555" class="">i</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">177</span><span sentence-index="13555" class="">]  is            exactly  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">177</span><span sentence-index="13555" class="">h</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13555</span><span sentence-index="13555" class=""> . </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">178</span><span sentence-index="13556" class=""> For  more  information  on  tuning  these  parameters,  refer  to  the            classic  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">178</span><span sentence-index="13556" class="">Numerical  Recipes  in  C</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13556</span><span sentence-index="13556" class=""> . </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13557</span><span sentence-index="13557" class="">  The  function  to  find  velocity  from  our            data  structure  would  be  as  follows. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span sentence-index="13558" class=""> Note  that  in  our  notation,                </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span>t</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span>[</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span>i</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span sentence-index="13558" class="">&#x2212;</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span sentence-index="13558" class="">1</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span sentence-index="13558" class="">]  is  behind  in  time            compared  to  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span sentence-index="13558" class="">t</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span sentence-index="13558" class="">[</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">180</span><span sentence-index="13558" class="">i</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13558</span><span sentence-index="13558" class=""> ],  so  we  are  using  the  backward  form. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">181</span><span sentence-index="13559" class="">           Your  program  needs  to  ensure  that  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">181</span><span sentence-index="13559" class="">t</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">181</span><span sentence-index="13559" class="">[</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">181</span><span sentence-index="13559" class="">i</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">181</span><span sentence-index="13559" class="">&#x2212;1]  exists            before  executing  this  function:</span></span></a></p><a id="I_programlisting6_id362709"><pre class="programlisting">Vector findVelocity (x[i-1], y[i-1], z[i-1], t[i-1], x[i], y[i], z[i], t[i]){

    float vx, vy, vz;

    vx = (x[i] &#x2212; x[i-1])/(t[i]-t[i-1]);
    vy = (y[i] &#x2212; y[i-1])/(t[i]-t[i-1]);
    vz = (z[i] &#x2212; z[i-1])/(t[i]-t[i-1]);

    vector velocity = {vx, vy, vz};

    return velocity;

}</pre></a><p><a id="I_programlisting6_id362709"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">184</span><span sentence-index="13562" class="">To  compute  the  acceleration  vector</span></span></a><a id="I_indexterm6_id362773" class="indexterm"></a><a id="I_indexterm6_id362780" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13564</span><span sentence-index="13564" class=""> ,  we  need  to  compare  two  velocities. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13565</span><span sentence-index="13565" class="">  However,  we  note  that        to  get  a  velocity,  we  need  two  data  points. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13566</span><span sentence-index="13566" class="">  Therefore,  a  total  of  three        data  points  is  required. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13567</span><span sentence-index="13567" class="">  The  acceleration  we  solve  for  will  actually  be        the  acceleration  for  the  middle  data  point  as  we  compare  the  backward  and        forward  difference. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">190</span><span sentence-index="13568" class=""> This  technique  is  named  the  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">190</span><span sentence-index="13568" class="">second-order        central  difference</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13568</span><span sentence-index="13568" class=""> . </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">191</span><span sentence-index="13569" class=""> In  </span></span></a><a id="I_indexterm6_id362797" class="indexterm"></a><a id="I_indexterm6_id362804" class="indexterm"><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">193</span><span sentence-index="13571" class="">general,  that  form  is  as  follows:</span></span></a></p><table style="border: 0; " class="simplelist"><tbody><tr><td><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">193</span><span sentence-index="13571" class="">f&apos;&apos;(x)  =  (f(x+2h)  &#x2013;  2f(x+h)  +  f(x))  /            h</span></span><sup><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">193</span><span sentence-index="13571" class="">2</span></span></sup></td></tr></tbody></table><p><a id="I_indexterm6_id362804" class="indexterm"><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13573</span><span sentence-index="13573" class="">This  allows  you  to  compute  the  acceleration  directly  without  first  finding  the  velocities. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">196</span><span sentence-index="13574" class="">           Here  again,  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">196</span><span sentence-index="13574" class="">f</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">196</span><span sentence-index="13574" class="">(</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">196</span><span sentence-index="13574" class="">x</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">196</span><span sentence-index="13574" class="">)  is  the  position  reported  by  the            sensor  and  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">196</span><span sentence-index="13574" class="">h</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13574</span><span sentence-index="13574" class="">  is  the  time  step  between  data  points. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">197</span><span sentence-index="13575" class=""> The  same  discussion  of                </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">197</span><span sentence-index="13575" class="">h</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13575</span><span sentence-index="13575" class="">  applies  here  as  well. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13576</span><span sentence-index="13576" class="">  Some  tuning  of  the  time  step  might  be  required            to  provide  a  stable  differential. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13577</span><span sentence-index="13577" class="">  Of  particular  note  with  central  difference  forms  is  that            periodic  functions  that  are  in  sync  with  your  time  step  may  result  in  zero  slope. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13578</span><span sentence-index="13578" class="">  If  the            motion  you  are  tracking  is  periodic,  you  should  take  care  to  avoid  a  time  step  near  the  period            of  oscillation. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">201</span><span sentence-index="13579" class=""> This  is  called  </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">201</span><span sentence-index="13579" class="">aliasing</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13579</span><span sentence-index="13579" class="">  and  is  a  problem  with  all  signal            analysis,  including  computer  graphics  displays. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13580</span><span sentence-index="13580" class="">  Also,  note  that  this  cannot  be  computed  until            at  least  three  time  steps  have  been  stored. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span sentence-index="13581" class=""> In  our  notation,                </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span>t</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span>[</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span>i</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span sentence-index="13581" class="">&#x2212;1]  is  the  center  data  point,                </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span>t</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span>[</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span>i</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span sentence-index="13581" class="">&#x2212;2]  the  backward  value,  and                </span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span sentence-index="13581" class="">t</span></span></em></span><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span sentence-index="13581" class="">[</span></span><span class="emphasis"><em><span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">203</span><span sentence-index="13581" class="">i</span></span></em></span><span class="nonQuoteStr"><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13581</span><span sentence-index="13581" class=""> ]  the  forward  value. </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">204</span><span sentence-index="13582" class=""> The  acceleration  function            would  therefore  be  as  follows:</span></span></a></p><a id="I_programlisting6_id362830"><pre class="programlisting">Vector findAcceleration (x[i-2], y[i-2], z[i-2], t[i-2], x[i-1], y[i-1], z[i-1], 
                         t[i-1], x[i], y[i], z[i], t[i] ){

    float ax, ay, az, h;
    vector acceleration;

    h = t[i]-t[i-1];

    ax = (x[i] &#x2212; 2*x[i-1] + x[i-2]) / h;
    ay = (y[i] &#x2212; 2*y[i-1] + y[i-2]) / h;
    az = (z[i] &#x2212; 2*z[i-1] + z[i-2]) / h;

    return acceleration = {ax, ay, az};
}</pre></a><p><a id="I_programlisting6_id362830"><span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13585</span><span sentence-index="13585" class="">Now,  let&apos;s  say  that  you  are  tracking  a  ball  in  someone&apos;s  hand. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13586</span><span sentence-index="13586" class="">  Until        he  lets  it  go,  the  velocity  and  acceleration  we  are  calculating  could        change  at  any  moment  in  any  number  of  ways. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13587</span><span sentence-index="13587" class="">  It  is  not  until  the  user  lets        go  of  the  ball  that  the  physics  we  have  discussed  takes  over. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13588</span><span sentence-index="13588" class="">  Hence,  you        have  to  optically  track  it  until  he  completes  the  throw. </span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13589</span><span sentence-index="13589" class="">  Once  the  ball  is        released,  the  physics  from  the  rest  of  this  book  applies! </span><span style="background-color: lightgray; padding: 4px;" class="spanSentenceIndexNumber">212</span><span sentence-index="13590" class=""> You  can  then  use        the  position  at  time  of  release,  the  velocity  vector,  and  the  acceleration        vector  to  plot  its  trajectory  in  the  </span></span></a><a id="I_indexterm6_id362892" class="indexterm"></a><a id="I_indexterm6_id362902" class="indexterm"><span><span style="margin-right: 5px; margin-left: 5px;" class="spanSentenceIndexNumber">13592</span><span sentence-index="13592" class="">game.</span></span></a></p></div></section><a id="I_indexterm6_id362902" class="indexterm">
</a></body></html>